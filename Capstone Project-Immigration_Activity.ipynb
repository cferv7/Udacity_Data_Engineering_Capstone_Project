{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration Activity of the People of Ecuador\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id, isnan, when, count, avg\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, date_format,to_date,to_timestamp\n",
    "from pyspark.sql.types import * \n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope\n",
    "\n",
    "In this project, we will aggregate I94 immigration data by destination city to form our first dimension table. Next we will aggregate city temperature data by city to form the second dimension table. The two datasets will be joined on destination city to form the fact table. The final database is optimized to query on immigration events to determine if temperature affects the selection of destination cities. We will also take a particular look at the immigration activity of the Ecuadorians. Spark will be used to process the data.\n",
    "\n",
    "#### Describe and Gather Data\n",
    "\n",
    "The I94 immigration data comes from the US National Tourism and Trade Office. It is provided in SAS7BDAT format which is a binary database storage format. Some relevant attributes include:\n",
    "- i94yr = 4 digit year\n",
    "- i94mon = numeric month\n",
    "- i94cit = 3 digit code of birth country\n",
    "- i94res = 3 digit code of residence country\n",
    "- i94port = 3 character code of destination USA city\n",
    "- arrdate = arrival date in the USA\n",
    "- i94mode = 1 digit travel code\n",
    "- i94addr = 2 letter code of US states\n",
    "- depdate = departure date from the USA\n",
    "- i94visa = reason for immigration\n",
    "\n",
    "The temperature data comes from Kaggle ([link](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)). It is provided in csv format. Some relevant attributes include:\n",
    "- AverageTemperature = average temperature (in Celsius)\n",
    "- City = city name\n",
    "- Country = country name\n",
    "- Latitude= latitude\n",
    "- Longitude = longitude\n",
    "\n",
    "The US demographics data comes from Opendatasoft ([link](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)). It is provided in csv format. Some relevant attributes include:\n",
    "- City = city name\n",
    "- State = state name\n",
    "- Total Population = total city population \n",
    "- Race = selection of White, Hispanic or Latino, Asian, Black or African-American, American Indian and Alaska Native\n",
    "- Count = Number Count based on respective Race selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in April 2016 I94 immigration data via Spark\n",
    "conf = SparkConf().setMaster(\"local[*]\").set(\"spark.network.timeout\", \"600s\")\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Capstone Project\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "i94_data = spark.read.parquet(\"sas_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate  ...  entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      CA  20582.0  ...     None        M   1976.0  10292016      F   None   \n",
       "1      NV  20591.0  ...     None        M   1984.0  10292016      F   None   \n",
       "2      WA  20582.0  ...     None        M   1987.0  10292016      M   None   \n",
       "3      WA  20588.0  ...     None        M   1987.0  10292016      F   None   \n",
       "4      WA  20588.0  ...     None        M   1988.0  10292016      M   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0      QF  9.495387e+10  00011       B1  \n",
       "1      VA  9.495562e+10  00007       B1  \n",
       "2      DL  9.495641e+10  00040       B1  \n",
       "3      DL  9.495645e+10  00040       B1  \n",
       "4      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Spark for data exploration\n",
    "i94_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many rows\n",
    "i94_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the temperature data into Pandas for exploration\n",
    "file = 'GlobalLandTemperaturesByCity.csv'\n",
    "df = pd.read_csv(file, sep=',', nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Ã…rhus   \n",
       "1  1743-12-01                 NaN                            NaN  Ã…rhus   \n",
       "2  1744-01-01                 NaN                            NaN  Ã…rhus   \n",
       "3  1744-02-01                 NaN                            NaN  Ã…rhus   \n",
       "4  1744-03-01                 NaN                            NaN  Ã…rhus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display first five entries of temperature data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clean the Data\n",
    "\n",
    "For the I94 immigration data, we want to drop all entries where the destination city code i94port is not a valid value (e.g., XXX, 99, etc) as described in I94_SAS_Labels_Description.SAS. For the temperature data, we want to drop all entries where AverageTemperature is Null value, then take the average yearly April temperature for each location and lastly add the i94port of the location in each entry. We would also change some of the columns from string to their appropriate data type. \n",
    "For the US demographics data, we extract the columns that we will need to perform our data analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the immigration data\n",
    "\n",
    "# Create a dictionary of valid i94 codes \n",
    "re_obj = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "i94port_valid = {}\n",
    "with open('i94port_valid.txt') as f:\n",
    "     for line in f:\n",
    "         match = re_obj.search(line)\n",
    "         i94port_valid[match[1]]=[match[2]]\n",
    "            \n",
    "def clean_i94_data(data):\n",
    "    '''\n",
    "    \n",
    "    Description: This function filter out entries where i94port codes are not valid\n",
    "    Arguments:\n",
    "        data: a Spark dataframe    \n",
    "    '''\n",
    "    \n",
    "    data = data.filter(data.i94port.isin(list(i94port_valid.keys())))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|i94port|\n",
      "+-------+\n",
      "|    LOS|\n",
      "|    LOS|\n",
      "|    LOS|\n",
      "|    LOS|\n",
      "|    LOS|\n",
      "|    HHW|\n",
      "|    HHW|\n",
      "|    HHW|\n",
      "|    HOU|\n",
      "|    LOS|\n",
      "|    NEW|\n",
      "|    LOS|\n",
      "|    WAS|\n",
      "|    LOS|\n",
      "|    LOS|\n",
      "|    MIA|\n",
      "|    SFR|\n",
      "|    HOU|\n",
      "|    HOU|\n",
      "|    LOS|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test clean_i94_data function\n",
    "i94_data_test = spark.read.parquet(\"sas_data/\")\n",
    "\n",
    "df_i94_test = clean_i94_data(i94_data_test)\n",
    "\n",
    "df_i94_test.select(df_i94_test.i94port).show(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean i94port\n",
    "df_i94_test.filter(df_i94_test.i94port == 'NaN').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean temperature data\n",
    "df_temp = spark.read.format(\"csv\").option(\"header\",\"true\").load(file)\n",
    "\n",
    "# Filter out entries with NaN average temperature\n",
    "df_temp = df_temp.filter(df_temp.AverageTemperature != 'NaN')\n",
    "\n",
    "# Change data type of dt from string to date\n",
    "df_temp = df_temp.withColumn(\"dt\", col(\"dt\").cast(\"date\"))\n",
    "\n",
    "\n",
    "# Change data type of Average Temperature from string to double\n",
    "df_temp = df_temp.withColumn(\"AverageTemperature\",col(\"AverageTemperature\").cast(\"Double\"))\n",
    "\n",
    "\n",
    "# Extract average temperature for the month of April for every city and country\n",
    "df_temp = df_temp.withColumn(\"Month\", month(\"dt\"))\n",
    "df_temp = df_temp.filter(col(\"Month\") == 4)\\\n",
    "                 .groupBy(\"City\", \"Country\", \"Latitude\", \"Longitude\") \\\n",
    "                 .agg(avg(\"AverageTemperature\").alias(\"AverageTemperature\"))\n",
    "\n",
    "# Remove duplicate locations\n",
    "# df_temp = df_temp.dropDuplicates(['City', 'Country'])\n",
    "\n",
    "@udf()\n",
    "def get_i94port(city):\n",
    "    '''\n",
    "    Descriptions: This function gets the corresponding i94 port code for the respective city\n",
    "    Arguments:\n",
    "        city: city name\n",
    "    '''\n",
    "    \n",
    "    for key in i94port_valid:\n",
    "        if city.lower() in i94port_valid[key][0].lower():\n",
    "            return key\n",
    "        \n",
    "# Add iport94 code based on city name\n",
    "df_temp = df_temp.withColumn(\"i94port\", get_i94port(df_temp.City))\n",
    "\n",
    "# Remove entries with iport94 is null\n",
    "df_temp = df_temp.filter(df_temp.i94port != 'null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------+---------+------------------+-------+\n",
      "|       City|             Country|Latitude|Longitude|AverageTemperature|i94port|\n",
      "+-----------+--------------------+--------+---------+------------------+-------+\n",
      "|       Aden|               Yemen|  13.66N|   45.41E| 26.58692753623188|    SRQ|\n",
      "|   Columbus|       United States|  32.95N|   85.21W|16.635823076923067|    COL|\n",
      "|    Durango|              Mexico|  24.92N|  104.63W|18.936804469273742|    DRO|\n",
      "|  Melbourne|           Australia|  37.78S|  144.41E|13.714534883720939|    MLB|\n",
      "|      Derby|      United Kingdom|  53.84N|    1.36W| 7.290939849624056|    DER|\n",
      "|   Montreal|              Canada|  45.81N|   72.69W|3.9470988593155876|    MON|\n",
      "|       Nice|              France|  44.20N|    6.71E| 7.833003759398493|    CND|\n",
      "| Washington|       United States|  39.38N|   76.99W|11.250669230769233|    WAS|\n",
      "|   Hamilton|              Canada|  42.59N|   80.73W| 6.224026615969584|    HAM|\n",
      "|   Veracruz|              Mexico|  18.48N|   96.34W|24.860569832402238|    VER|\n",
      "| Alexandria|       United States|  39.38N|   76.99W|11.250669230769233|    AXB|\n",
      "|Baton Rouge|       United States|  29.74N|   90.46W|20.316677884615384|    BTN|\n",
      "|    Spokane|       United States|  47.42N|  117.24W| 7.296361256544501|    SPO|\n",
      "|  San Diego|       United States|  32.95N|  117.77W|14.309703030303028|    SDP|\n",
      "|     Naples|               Italy|  40.99N|   14.91E|12.057161654135344|    APF|\n",
      "|   San Juan|         Puerto Rico|  18.48N|   65.92W| 24.46721142857141|    SAJ|\n",
      "|  Vancouver|              Canada|  49.03N|  122.45W| 6.696088397790051|    VAN|\n",
      "|       Goma|Congo (Democratic...|   2.41S|   29.73E|18.647248275862065|    AGM|\n",
      "|    Madison|       United States|  42.59N|   89.45W| 8.065745247148289|    HSV|\n",
      "|     London|      United Kingdom|  52.24N|    0.00W| 8.074078947368422|    NWL|\n",
      "+-----------+--------------------+--------+---------+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "df_temp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Define the Data Model\n",
    "\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "The first dimension table will contain events from the I94 immigration data. The columns below will be extracted from the immigration dataframe:\n",
    "- i94yr = 4 digit year\n",
    "- i94mon = numeric month\n",
    "- i94cit = 3 digit code of birth country\n",
    "- i94res = 3 digit code of residence country\n",
    "- i94port = 3 character code of destination USA city\n",
    "- arrdate = arrival date in the USA\n",
    "- i94mode = 1 digit travel code\n",
    "- i94addr = 2 letter code of US states\n",
    "- depdate = departure date from the USA\n",
    "- i94visa = reason for immigration\n",
    "\n",
    "The second dimension table will contain city temperature data. The columns below will be extracted from the temperature dataframe:\n",
    "- i94port = 3 character code of destination city (mapped from immigration data during cleanup step)\n",
    "- AverageTemperature = average temperature\n",
    "- City = city name\n",
    "- Country = country name\n",
    "- Latitude= latitude\n",
    "- Longitude = longitude\n",
    "\n",
    "The third dimension table will contain US demographics data. The columns below will be extracted from the us demographics dataframe:\n",
    "- City = city name\n",
    "- State = state name\n",
    "- Total Population = total city population \n",
    "- Race = selection of White, Hispanic or Latino, Asian, Black or African-American, American Indian and Alaska Native\n",
    "- Count = Number Count based on respective Race selection\n",
    "\n",
    "\n",
    "The final table will contain information from the I94 immigration data joined with the city temperature data on i94port:\n",
    "- i94yr = 4 digit year\n",
    "- i94mon = numeric month\n",
    "- i94res = 3 digit code of residence country\n",
    "- i94cit = 3 digit code of birth country\n",
    "- i94port = 3 character code of destination city\n",
    "- arrdate = arrival date\n",
    "- destination_city = full name of city\n",
    "- depdate = departure date\n",
    "- i94visa = reason for immigration\n",
    "- hispanic_ratio = percentage of Hispanic or Latino people in the city\n",
    "- AverageTemperature = average temperature of destination city\n",
    "\n",
    "The tables will be saved to Parquet files partitioned by city (i94port).\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "The pipeline steps are described below:\n",
    "1. Clean I94 data as described in step 2 to create Spark dataframe df_immigration\n",
    "2. Clean temperature data as described in step 2 to create Spark dataframe df_temp (already performed)\n",
    "3. Clean demographics data as described in step 2 to create Spark dataframe df_demographics \n",
    "4. Create immigration dimension table by selecting relevant columns from df_immigration and write to parquet file partitioned by i94port\n",
    "5. Create temperature dimension table by selecting relevant columns from df_temp and write to parquet file partitioned by i94port\n",
    "6. Create demographics dimension table by selecting relevant columns from df_temp and write to parquet file partitioned by i94port\n",
    "7. Create final table by joining immigration, temperature, demographics dimension tables on i94port and write to parquet file partitioned by i94port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Run Pipelines to Model the Data\n",
    "\n",
    "4.1 Create the data model\n",
    "\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain immigration data\n",
    "immigration_data = spark.read.parquet(\"sas_data/\")\n",
    "\n",
    "# Clean i94 immigration data\n",
    "df_immigration = clean_i94_data(immigration_data)\n",
    "\n",
    "# Extract columns for immigration dimension table\n",
    "immigration_table = df_immigration.select(\n",
    "                                        df_immigration.i94yr.alias(\"i94yr\"),\n",
    "                                        df_immigration.i94mon.alias(\"i94mon\"),\n",
    "                                        df_immigration.i94cit.alias(\"i94cit\"),\n",
    "                                        df_immigration.i94res.alias(\"i94res\"),\n",
    "                                        df_immigration.i94port.alias(\"i94port\"),\n",
    "                                        df_immigration.arrdate.alias(\"arrdate\"),\n",
    "                                        df_immigration.i94mode.alias(\"i94mode\"),\n",
    "                                        df_immigration.i94addr.alias(\"i94addr\"),\n",
    "                                        df_immigration.depdate.alias(\"depdate\"),\n",
    "                                        df_immigration.i94visa.alias(\"i94visa\")\n",
    "                                    ).filter(df_immigration.i94addr != 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write immigration dimension table to parquet files partitioned by i94port\n",
    "immigration_table.write.mode(\"overwrite\").partitionBy(\"i94port\").parquet(\"/results/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+-------+-------+-------+-------+-------+-------+\n",
      "| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94visa|\n",
      "+------+------+------+------+-------+-------+-------+-------+-------+-------+\n",
      "|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|    1.0|\n",
      "|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|    1.0|\n",
      "|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|    1.0|\n",
      "|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|    1.0|\n",
      "|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|    1.0|\n",
      "|2016.0|   4.0| 245.0| 464.0|    HHW|20574.0|    1.0|     HI|20579.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 464.0|    HHW|20574.0|    1.0|     HI|20586.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 464.0|    HHW|20574.0|    1.0|     HI|20586.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 464.0|    HOU|20574.0|    1.0|     FL|20581.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 464.0|    LOS|20574.0|    1.0|     CA|20581.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 504.0|    NEW|20574.0|    1.0|     MA|20576.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 504.0|    WAS|20574.0|    1.0|     VA|20596.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 504.0|    LOS|20574.0|    1.0|     CA|20577.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 504.0|    LOS|20574.0|    1.0|     CA|20577.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 504.0|    MIA|20574.0|    1.0|     FL|20581.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 528.0|    SFR|20574.0|    1.0|     CA|   null|    2.0|\n",
      "|2016.0|   4.0| 245.0| 582.0|    HOU|20574.0|    1.0|     TX|20583.0|    1.0|\n",
      "|2016.0|   4.0| 245.0| 582.0|    HOU|20574.0|    1.0|     TX|20583.0|    1.0|\n",
      "|2016.0|   4.0| 245.0| 582.0|    LOS|20574.0|    1.0|     CA|20575.0|    2.0|\n",
      "|2016.0|   4.0| 245.0| 690.0|    DAL|20574.0|    1.0|     NV|20578.0|    2.0|\n",
      "+------+------+------+------+-------+-------+-------+-------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract & arrange columns for temperature dimension table\n",
    "temp_table = df_temp.select([\"i94port\", \"City\", \"Country\", \"Latitude\", \"Longitude\", \"AverageTemperature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write temperature dimension table to parquet files paritioned by i94port\n",
    "temp_table.write.mode(\"overwrite\").partitionBy(\"i94port\").parquet(\"/results/temperature.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------------+--------+---------+------------------+\n",
      "|i94port|       City|             Country|Latitude|Longitude|AverageTemperature|\n",
      "+-------+-----------+--------------------+--------+---------+------------------+\n",
      "|    SRQ|       Aden|               Yemen|  13.66N|   45.41E| 26.58692753623188|\n",
      "|    COL|   Columbus|       United States|  32.95N|   85.21W|16.635823076923067|\n",
      "|    DRO|    Durango|              Mexico|  24.92N|  104.63W|18.936804469273742|\n",
      "|    MLB|  Melbourne|           Australia|  37.78S|  144.41E|13.714534883720939|\n",
      "|    DER|      Derby|      United Kingdom|  53.84N|    1.36W| 7.290939849624056|\n",
      "|    MON|   Montreal|              Canada|  45.81N|   72.69W|3.9470988593155876|\n",
      "|    CND|       Nice|              France|  44.20N|    6.71E| 7.833003759398493|\n",
      "|    WAS| Washington|       United States|  39.38N|   76.99W|11.250669230769233|\n",
      "|    HAM|   Hamilton|              Canada|  42.59N|   80.73W| 6.224026615969584|\n",
      "|    VER|   Veracruz|              Mexico|  18.48N|   96.34W|24.860569832402238|\n",
      "|    AXB| Alexandria|       United States|  39.38N|   76.99W|11.250669230769233|\n",
      "|    BTN|Baton Rouge|       United States|  29.74N|   90.46W|20.316677884615384|\n",
      "|    SPO|    Spokane|       United States|  47.42N|  117.24W| 7.296361256544501|\n",
      "|    SDP|  San Diego|       United States|  32.95N|  117.77W|14.309703030303028|\n",
      "|    APF|     Naples|               Italy|  40.99N|   14.91E|12.057161654135344|\n",
      "|    SAJ|   San Juan|         Puerto Rico|  18.48N|   65.92W| 24.46721142857141|\n",
      "|    VAN|  Vancouver|              Canada|  49.03N|  122.45W| 6.696088397790051|\n",
      "|    AGM|       Goma|Congo (Democratic...|   2.41S|   29.73E|18.647248275862065|\n",
      "|    HSV|    Madison|       United States|  42.59N|   89.45W| 8.065745247148289|\n",
      "|    NWL|     London|      United Kingdom|  52.24N|    0.00W| 8.074078947368422|\n",
      "+-------+-----------+--------------------+--------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_demographics  2891\n"
     ]
    }
   ],
   "source": [
    "demo = 'us-cities-demographics.csv'\n",
    "df_demographics = spark.read.csv(demo, header='true', sep=\";\")\n",
    "print('df_demographics ', df_demographics.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract appropriate columans and add iport94 code based on city name\n",
    "# And in addition, dropping null rows for i94port\n",
    "\n",
    "df_demographics = df_demographics.select([\"City\", \"State\", \"Total Population\", \"Race\", \"Count\"])\n",
    "df_demographics = df_demographics.withColumn(\"i94port\", get_i94port(df_demographics.City))\n",
    "df_demographics = df_demographics.filter(df_demographics.i94port != 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "      <th>i94port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>281913</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "      <td>NEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>118661</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1343</td>\n",
       "      <td>PIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1567442</td>\n",
       "      <td>Asian</td>\n",
       "      <td>122721</td>\n",
       "      <td>PHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>Florida</td>\n",
       "      <td>74015</td>\n",
       "      <td>White</td>\n",
       "      <td>50169</td>\n",
       "      <td>FMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laredo</td>\n",
       "      <td>Texas</td>\n",
       "      <td>255789</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1253</td>\n",
       "      <td>LCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Allen</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>120207</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>22304</td>\n",
       "      <td>MCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Haven</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>130310</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>2205</td>\n",
       "      <td>NWH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Utah</td>\n",
       "      <td>192660</td>\n",
       "      <td>Asian</td>\n",
       "      <td>13153</td>\n",
       "      <td>SLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>88161</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>39107</td>\n",
       "      <td>FOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>3971896</td>\n",
       "      <td>White</td>\n",
       "      <td>2177650</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             City         State Total Population  \\\n",
       "0          Newark    New Jersey           281913   \n",
       "1          Peoria      Illinois           118661   \n",
       "2    Philadelphia  Pennsylvania          1567442   \n",
       "3      Fort Myers       Florida            74015   \n",
       "4          Laredo         Texas           255789   \n",
       "5           Allen  Pennsylvania           120207   \n",
       "6       New Haven   Connecticut           130310   \n",
       "7  Salt Lake City          Utah           192660   \n",
       "8         Suffolk      Virginia            88161   \n",
       "9     Los Angeles    California          3971896   \n",
       "\n",
       "                                Race    Count i94port  \n",
       "0                              White    76402     NEW  \n",
       "1  American Indian and Alaska Native     1343     PIA  \n",
       "2                              Asian   122721     PHI  \n",
       "3                              White    50169     FMY  \n",
       "4  American Indian and Alaska Native     1253     LCB  \n",
       "5          Black or African-American    22304     MCA  \n",
       "6  American Indian and Alaska Native     2205     NWH  \n",
       "7                              Asian    13153     SLC  \n",
       "8          Black or African-American    39107     FOK  \n",
       "9                              White  2177650     LOS  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary views of the immigration, temperature, and demographics data\n",
    "df_immigration.createOrReplaceTempView(\"immigration_view\")\n",
    "df_temp.createOrReplaceTempView(\"temp_view\")\n",
    "df_demographics.createOrReplaceTempView(\"demogr_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final table by joining the immigration, temperature, and demographics views\n",
    "fact_table = spark.sql('''\n",
    "    SELECT immigration_view.i94yr as year,\n",
    "            immigration_view.i94mon as month,\n",
    "            immigration_view.i94cit as birth_country,\n",
    "            immigration_view.i94res as residence_country,\n",
    "            immigration_view.i94port as i94port,\n",
    "            immigration_view.arrdate as arrival_date,\n",
    "            temp_view.City as destination_city,\n",
    "            immigration_view.depdate as departure_date,\n",
    "            immigration_view.i94visa as visa_type,\n",
    "            (demogr_view.Count / demogr_view.`Total Population`) as hispanic_ratio,\n",
    "            temp_view.AverageTemperature as temperature\n",
    "\n",
    "FROM immigration_view\n",
    "    JOIN temp_view ON (immigration_view.i94port = temp_view.i94port)\n",
    "    JOIN demogr_view ON (immigration_view.i94port = demogr_view.i94port)\n",
    "    WHERE demogr_view.Race = 'Hispanic or Latino'\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write fact table to parquet files paritioned by i94port\n",
    "fact_table.write.mode(\"overwrite\").partitionBy(\"i94port\").parquet(\"/results/fact.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>birth_country</th>\n",
       "      <th>residence_country</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>hispanic_ratio</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20561.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20580.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20629.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20578.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20578.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20579.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20579.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20560.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  birth_country  residence_country i94port  arrival_date  \\\n",
       "0  2016.0    4.0          135.0              135.0     SRQ       20561.0   \n",
       "1  2016.0    4.0          689.0              689.0     SRQ       20560.0   \n",
       "2  2016.0    4.0          311.0              353.0     SRQ       20560.0   \n",
       "3  2016.0    4.0          298.0              298.0     SRQ       20560.0   \n",
       "4  2016.0    4.0          298.0              298.0     SRQ       20560.0   \n",
       "5  2016.0    4.0          298.0              298.0     SRQ       20560.0   \n",
       "6  2016.0    4.0          296.0              296.0     SRQ       20560.0   \n",
       "7  2016.0    4.0          296.0              296.0     SRQ       20560.0   \n",
       "8  2016.0    4.0          296.0              296.0     SRQ       20560.0   \n",
       "9  2016.0    4.0          296.0              296.0     SRQ       20560.0   \n",
       "\n",
       "  destination_city  departure_date  visa_type  hispanic_ratio  temperature  \n",
       "0             Aden         20580.0        1.0        0.223965    26.586928  \n",
       "1             Aden         20567.0        2.0        0.223965    26.586928  \n",
       "2             Aden         20571.0        2.0        0.223965    26.586928  \n",
       "3             Aden         20629.0        2.0        0.223965    26.586928  \n",
       "4             Aden         20578.0        2.0        0.223965    26.586928  \n",
       "5             Aden         20578.0        2.0        0.223965    26.586928  \n",
       "6             Aden         20579.0        2.0        0.223965    26.586928  \n",
       "7             Aden         20579.0        2.0        0.223965    26.586928  \n",
       "8             Aden         20574.0        1.0        0.223965    26.586928  \n",
       "9             Aden         20571.0        2.0        0.223965    26.586928  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_table.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_check(df, description):\n",
    "    '''\n",
    "    Description: This function performs data quality checks to ensure that the dataframe consists of rows \n",
    "    Arguments:\n",
    "        df: Spark dataframe\n",
    "        description: brief description of the dataframe\n",
    "    '''\n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(description))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records.\".format(description, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for us_demographic table with 878 records.\n",
      "Data quality check passed for immigration table with 3092066 records.\n"
     ]
    }
   ],
   "source": [
    "# Perform data quality check\n",
    "quality_check(df_demographics, \"us_demographic table\")\n",
    "quality_check(df_immigration, \"immigration table\")\n",
    "quality_check(df_temp, \"temperature table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53443, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering the table to show data related to Ecuador. The code for Ecucador is 692\n",
    "\n",
    "ecuador_data = fact_table.filter((\"birth_country = 692.0 OR residence_country = 692.0\")).toPandas()  \n",
    "ecuador_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>birth_country</th>\n",
       "      <th>residence_country</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>hispanic_ratio</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20563.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20578.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20563.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20563.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20563.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20570.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>SRQ</td>\n",
       "      <td>20563.0</td>\n",
       "      <td>Aden</td>\n",
       "      <td>20570.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.223965</td>\n",
       "      <td>26.586928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month  birth_country  residence_country i94port  arrival_date  \\\n",
       "0  2016.0    4.0          692.0              692.0     SRQ       20563.0   \n",
       "1  2016.0    4.0          692.0              692.0     SRQ       20563.0   \n",
       "2  2016.0    4.0          692.0              692.0     SRQ       20563.0   \n",
       "3  2016.0    4.0          692.0              692.0     SRQ       20563.0   \n",
       "4  2016.0    4.0          692.0              692.0     SRQ       20563.0   \n",
       "\n",
       "  destination_city  departure_date  visa_type  hispanic_ratio  temperature  \n",
       "0             Aden         20578.0        2.0        0.223965    26.586928  \n",
       "1             Aden         20573.0        2.0        0.223965    26.586928  \n",
       "2             Aden         20573.0        2.0        0.223965    26.586928  \n",
       "3             Aden         20570.0        2.0        0.223965    26.586928  \n",
       "4             Aden         20570.0        2.0        0.223965    26.586928  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecuador_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecuador_data['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94port</th>\n",
       "      <th>count</th>\n",
       "      <th>hispanic_ratio</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIA</td>\n",
       "      <td>14908</td>\n",
       "      <td>0.725510</td>\n",
       "      <td>22.596529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYC</td>\n",
       "      <td>14830</td>\n",
       "      <td>0.290644</td>\n",
       "      <td>7.966164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOS</td>\n",
       "      <td>6330</td>\n",
       "      <td>0.487609</td>\n",
       "      <td>18.309527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FTL</td>\n",
       "      <td>4513</td>\n",
       "      <td>0.157615</td>\n",
       "      <td>22.596529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORL</td>\n",
       "      <td>4426</td>\n",
       "      <td>0.329643</td>\n",
       "      <td>21.882888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NEW</td>\n",
       "      <td>1622</td>\n",
       "      <td>0.356252</td>\n",
       "      <td>16.548255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1184</td>\n",
       "      <td>0.040211</td>\n",
       "      <td>14.354050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHI</td>\n",
       "      <td>1150</td>\n",
       "      <td>0.288810</td>\n",
       "      <td>9.288686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOU</td>\n",
       "      <td>863</td>\n",
       "      <td>0.447288</td>\n",
       "      <td>20.302892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SFR</td>\n",
       "      <td>545</td>\n",
       "      <td>0.152765</td>\n",
       "      <td>13.638939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  i94port  count  hispanic_ratio  temperature\n",
       "0     MIA  14908        0.725510    22.596529\n",
       "1     NYC  14830        0.290644     7.966164\n",
       "2     LOS   6330        0.487609    18.309527\n",
       "3     FTL   4513        0.157615    22.596529\n",
       "4     ORL   4426        0.329643    21.882888\n",
       "5     NEW   1622        0.356252    16.548255\n",
       "6     ATL   1184        0.040211    14.354050\n",
       "7     CHI   1150        0.288810     9.288686\n",
       "8     HOU    863        0.447288    20.302892\n",
       "9     SFR    545        0.152765    13.638939"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecuador_data.groupby('i94port').agg({'count':np.size, 'hispanic_ratio': np.mean, 'temperature': np.mean})\\\n",
    "                                .sort_values('count', ascending=False).reset_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------+---------+------------------+-------+\n",
      "| City|Country|Latitude|Longitude|AverageTemperature|i94port|\n",
      "+-----+-------+--------+---------+------------------+-------+\n",
      "|Quito|Ecuador|   0.80S|   77.95W| 16.85527142857142|    UIO|\n",
      "+-----+-------+--------+---------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding out the average April temperature in Ecuador\n",
    "ecuador_temp = df_temp.filter(col(\"Country\") == \"Ecuador\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "We learned that the most popular city for Ecuardorians to immigrate to in April 2016 is Miami, followed by New York City (NYC). Itâ€™s important to note that NYCâ€™s temperature is far below the average temperature for Ecuador and hispanic ratio is about a third of the population. Looking at the top ten cities, the temperature and the hispanic ratio does not seem to play a major role in city selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary\n",
    "\n",
    "The first dimension table will contain events from the I94 immigration data. The columns below will be extracted from the immigration dataframe:\n",
    "- i94yr = 4 digit year\n",
    "- i94mon = numeric month\n",
    "- i94cit = 3 digit code of birth country\n",
    "- i94res = 3 digit code of residence country\n",
    "- i94port = 3 character code of destination USA city\n",
    "- arrdate = arrival date in the USA\n",
    "- i94mode = 1 digit travel code\n",
    "- i94addr = 2 letter code of US states\n",
    "- depdate = departure date from the USA\n",
    "- i94visa = reason for immigration\n",
    "\n",
    "The second dimension table will contain city temperature data. The columns below will be extracted from the temperature dataframe:\n",
    "- i94port = 3 character code of destination city (mapped from immigration data during cleanup step)\n",
    "- AverageTemperature = average temperature\n",
    "- City = city name\n",
    "- Country = country name\n",
    "- Latitude= latitude\n",
    "- Longitude = longitude\n",
    "\n",
    "The third dimension table will contain US demographics data. The columns below will be extracted from the us demographics dataframe:\n",
    "- City = city name\n",
    "- State = state name\n",
    "- Total Population = total city population \n",
    "- Race = selection of White, Hispanic or Latino, Asian, Black or African-American, American Indian and Alaska Native\n",
    "- Count = Number Count based on respective Race selection\n",
    "\n",
    "The fact table will contain information from the I94 immigration data joined with the city temperature data and the demographics data on i94port:\n",
    "- i94yr = 4 digit year\n",
    "- i94mon = numeric month\n",
    "- i94res = 3 digit code of residence country\n",
    "- i94cit = 3 digit code of birth country\n",
    "- i94port = 3 character code of destination city\n",
    "- arrdate = arrival date\n",
    "- destination_city = full name of city\n",
    "- depdate = departure date\n",
    "- i94visa = reason for immigration\n",
    "- hispanic_ratio = percentage of hispanic people in the city\n",
    "- AverageTemperature = average temperature of destination city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Complete Project Write Up\n",
    "\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "    * Spark can be better used in batch processing, compared with other data loading methods (flink is more suitable for real-time flow processing),Spark has an advantage in dealing with large files. After grouping the data to a smaller size, Pandas was then used to analyze the data further. \n",
    "* Propose how often the data should be updated and why.\n",
    "    * The immigration data should be updated yearly (or at the same frequency that the right authority releases the data)\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    "    * The data was increased by 100x.\n",
    "        * If the increase is more than 100 times, Spark cannot be executed on a local device. Spark cluster on Hadoop is needed to meet the data needs.  After grouping the data, the analysis could be continued with Pandas, the same way that it has been done here.\n",
    "    * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "        * If the data needed to populate a dashboard on a daily basis, it would help to use a workflow orchestration tool, such as Apache Airflow, Luigi, etc to schedule and execute the task. It would also help if the dashboard was connected to a real-time database.  \t\n",
    "    * The database needed to be accessed by 100+ people.\n",
    "        * From the current situation, my project list may not have as many visitors, but in terms of access, it could be handled by any database. But if this number becomes too large, then perhaps hosting it on a cloud provider, such as AWS, would help with the load.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
